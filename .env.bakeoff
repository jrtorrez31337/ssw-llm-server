# SSW AI Inference Platform â€” Model Bakeoff Stack
# Usage: docker compose -f docker-compose.bakeoff.yml --env-file .env.bakeoff up -d

# Model mount (host path)
MODEL_REPO=/data/models

# Bakeoff registry file
BAKEOFF_MODELS_YAML_PATH=./gateway/models.bakeoff.yaml

# Host ports (isolated from primary stack)
BAKEOFF_GATEWAY_PORT=8100
BAKEOFF_LOADER_PORT=8111
BAKEOFF_REDIS_PORT=6380

# Loader dynamic worker host port range
BAKEOFF_DYNAMIC_PORT_START=9100
BAKEOFF_DYNAMIC_PORT_END=9199

# GPU count visible to loader allocator
BAKEOFF_NUM_GPUS=2
